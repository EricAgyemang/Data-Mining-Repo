---
title: "Homework"
author: "ERIC AGYEMANG"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

p= c(0.1,0.15,0.2,0.2,0.55,0.6,0.6,0.6,0.65,0.7,0.75)

```

Majority  aprroach
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

sum(p >=0.5) > sum(p < 0.5)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##REGRESSION MODELLING PROBLEM USING CARET##


```{r}
library(caret)
library(lattice)
library(ggplot2)
library(mlbench)
library(survival)
library(parallel)
library(splines)
library(plyr)
library(gbm)
library(glmnet)
library(MASS)
library(C50)
library(naivebayes)
library(klaR)
library(kernlab)
library(Matrix)
library(foreach)
library(ISLR)
```


Loaind data set.
```{r}
data("iris")
iris$Species = as.factor(iris$Species)
head(iris)
```



Getting all list of algorithm that CARET supports.
```{r}
names(getModelInfo())
```

Splitting with CARET,we create testing and training data set using CARET.This will enable us develop and evaluate our model.
```{r}
inTrain = createDataPartition(y = iris$Species, p = .75, list = FALSE)
training = iris[inTrain,]
testing = iris[-inTrain,]
```

Next,we create the cross validationg method that will be used by CARET to create the training sets.
```{r}
fitControl <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 10)
```

Now we ready to develop the model.we make use of the train function in CARET to regress the dependant variable onto all of other covariates.
```{r}
set.seed(12345)
gbmFit1 <- train(Species ~ ., data = training, 
                 method = "gbm", 
                 trControl = fitControl,
                 verbose = FALSE)
```

We use CARET to choose our final model thus interaction depth of 1,number trees at 50, accuracay of 94% and a kappa of 90%
```{r}
gbmFit1
plot(gbmFit1)
```

Using the training model to make our predictions.As we can see there is 99% probability that the first flow in the data set is a setosa species.

```{r}
predict(gbmFit1, newdata = head(testing), type = "prob")
```


```{r}
summary(iris)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 5

```{r}
p= c(0.1, 0.15, 0.2, 0.2, 0.55, 0.6, 0.6, 0.65, 0.7, 0.75)
```
There are two commmon ways to combine these results together into a single class prediction.One is amajority approach and the second is average approach.

## Majority Approach
```{r}
sum(p >= 0.5) > sum(p < 0.5)

```
The number of red predictions is greater than the number of green predictions based on a 50% threshold,thus RED

## Average Approach
```{r}
mean(p)
```
The average of the probabilities is less than the 50% threshol,thus GREEN


## Question 8
a. splitting the data set into training and test set.
```{r}
library(ISLR)
attach(carseats)
set.seed(1)
train = sample(1:nrow(carseats), nrow(carseats)/2)
```


